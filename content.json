{"meta":{"title":"Allen's Blog","subtitle":null,"description":"Share some of my idea","author":"Allen","url":"http://xueyaodeai.github.io"},"pages":[{"title":"About","date":"2016-11-27T08:56:16.000Z","updated":"2016-04-18T16:06:36.000Z","comments":true,"path":"about/index.html","permalink":"http://xueyaodeai.github.io/about/index.html","excerpt":"","text":""},{"title":"Categories","date":"2016-11-27T08:56:16.000Z","updated":"2016-04-18T15:49:04.000Z","comments":true,"path":"categories/index.html","permalink":"http://xueyaodeai.github.io/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2016-11-27T08:56:16.000Z","updated":"2016-04-18T15:49:04.000Z","comments":true,"path":"tags/index.html","permalink":"http://xueyaodeai.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Hello World","slug":"Hello-World","date":"2016-08-09T14:54:03.000Z","updated":"2016-08-09T14:54:03.000Z","comments":true,"path":"2016/08/09/Hello-World/","link":"","permalink":"http://xueyaodeai.github.io/2016/08/09/Hello-World/","excerpt":"","text":"","categories":[],"tags":[],"keywords":[]},{"title":"关于公司项目的测试优化方案","slug":"关于公司项目的测试优化方案","date":"2016-03-27T13:53:06.000Z","updated":"2016-03-27T15:58:47.000Z","comments":true,"path":"2016/03/27/关于公司项目的测试优化方案/","link":"","permalink":"http://xueyaodeai.github.io/2016/03/27/关于公司项目的测试优化方案/","excerpt":"","text":"前言 就目前而言，公司的自动化测试最主要的发展方向还是自动验收测试，我这个季度的主要工作都是在提高自动验收测试的测试覆盖率，尽可能地保证要发布的版本在 BVT 案例上没有出现问题。这个思路本身是没有什么问题的，但是随着版本越来越多，积累的 BVT 案例也就越来越多，需要完成一次自动验收测试的时间已经远远超过之前的预期，而且项目里已经对验收测试过度依赖了。 正文现状我们现在提倡“以客户为中心，产品需要满足客户的需求”，从这方面来说，持续维护和发展自动验收测试是一个非常不错的选择，因为现有的验收测试案例大部分是以用户使用场景来设计的，同时尽可能覆盖多种条件。除此之外，无论是开发人员、测试人员还是版本经理，目前都倾向于使用大范围地这种测试方式： 有了验收测试，开发人员可以把大部分测试工作（比如单元测试）转交给别人，他们只需要对自己的代码进行非常简单的验证即可，大大节省了他们的时间。 有了验收测试，测试人员可以跳过这部分的功能测试，把更多时间用于验证新功能或者部分功能的改动 有了验收测试，版本经理可以根据验收测试的结果判断这个版本能不能发布，有没有风险。 ！！！但是，自动验收测试不是万能药，不是所有的东西都可以直接交给它搞定的。 目前的问题现在项目组的自动验收测试的流程如下： 使用最新代码构建新版本； 构建完成后通过 Jenkins 或者手工部署到测试环境； 通过测试平台将所有的验收测试案例在这个测试环境中运行； 案例全部执行完成后，汇总测试结果提交到统一的平台上，版本经理到上面查看测试报告，然后决定这个版本能不能正常发布。 在这个流程中，为了保证发布版本的质量，一般验收测试的成功率要在90%以上，并且没有严重问题才可以发布。然而，自动验收测试的时间很长，而且还在持续增长，而且我们很可能遇到下面这种情形： 从自动验收测试中得到的仅仅是失败的案例，需要进一步根据日志或者其他东西来追溯失败的根源，确认这个失败案例到底是不是一个 bug。这个流程的耗时太长了，而且会经常因为环境问题毁掉整个验收测试。然后开发人员着手修复这个问题，修复的成果也要到第二天才能确认，反馈根本没有办法即时传达。 测试的价值体现正常情况下，除了需求评审、设计案例，我们测试人员的主要工作在于发现 bug，然后将提交给开发，接下来修复 bug 的工作就交接给开发人员了，我们就此止步。 那么从“以客户为中心”这个角度出发，自动验收测试中失败的案例如何体现出价值，如何让用户受益？ 结论是：失败的案例并没有让用户直接受益。真正能让用户受益的是 bug 的修复。 要修复一个 bug，你首先要找出 bug，而这个依赖于捕获 bug 的测试。因此，从案例不通过到 bug 修复的整个流程中，只有最后一步才能产生价值。然而，在自动验收测试中，这个流程的步骤太多了，耗时太长了，缺乏理想反馈回路的基本属性： 迅捷。没有开发人员愿意等上数个小时或者数日来弄清楚他们的代码改动是否起作用。有时候，代码改动并不起作用——人无完人——反馈回路需要运行多次。更加迅捷的反馈回路带来更加迅捷的代码修复。如果回路足够迅速，开发人员甚至可以在签入代码改动前就运行测试。 可靠。没有开发人员愿意花费数个小时对测试进行排错，却发现只是测试不稳定。不稳定的测试降低了开发人员对测试的信任，结果就是不稳定的测试常常被忽略，即使在它们发现了真正的产品问题的时候。目前，自动验收测试这方面的问题还是比较严重的，很多失败的案例到最后发现是环境问题。 隔离故障点。为修复一个bug，开发人员需要明确找到引起bug的那些行代码。当产品包含数百万行代码，bug可能存在于任何地方的时候，这像是大海捞针。自动验收测试的失败案例往往只包含简单的错误信息，需要花费大量的时间通过日志排查错误的代码，效率相当低下。 下一步的完善点自动验收测试的主要作用应该是用于确保即将发布的最后版本没有问题，而不是尽可能找出所有的 bug。 将自动验收测试用于日常版本的质量保证是不恰当的，它过于臃肿，规模太过庞大。现在的验收测试案例往往包含了很多个测试点，出现失败案例要花很多时间去排查出错的代码，同时这些测试点交叉出现在多个测试案例中，使得自动验收测试的完成时间很长，综上两点使得日常版本构建的反馈不理想。 在日常测试版本的快速迭代中，我们应该考虑用更小规模的测试——单元测试，来保证质量。 单元测试具有迅捷性。我们只需要构建小的单元进行测试，测试也趋向于小规模。这样的小粒度的测试相比及自动验收测试，反馈更快，更迅捷。 单元测试具有可靠性。简单的系统和小的单元一般倾向于较少受到测试不稳定的影响——尤其在封闭测试的实践中——将彻底地去除不稳定性。 单元测试会隔离故障点。纵然产品包含数百万行代码，如果单元测试未通过，伱只需要查找被测单元就能找到bug。比起自动验收测试，单元测试的错误代码的定位速度要快无数倍。 当目前版本的功能已经稳定时，我们可以考虑构建当前版本的里程碑。这个时候，我们就应该使用自动验收测试，来保证系统整体功能的良好运作。 补充点鉴于我们产品的部分功能是只在 UI 上有效的，我们也应该考虑再加入一部分浏览器的端对端测试，以此来保证产品 UI 部分功能的有效性。 通过 casperjs 或者 nightmarejs 框架可以在不使用浏览器的情况下直接测试页面功能的有效性。","categories":[],"tags":[{"name":"测试","slug":"测试","permalink":"http://xueyaodeai.github.io/tags/测试/"},{"name":"自动化","slug":"自动化","permalink":"http://xueyaodeai.github.io/tags/自动化/"}],"keywords":[]},{"title":"自动化技术构想","slug":"jenkins-and-docker","date":"2016-03-02T16:10:06.000Z","updated":"2016-03-02T17:00:42.000Z","comments":true,"path":"2016/03/03/jenkins-and-docker/","link":"","permalink":"http://xueyaodeai.github.io/2016/03/03/jenkins-and-docker/","excerpt":"","text":"目前VTT的持续集成工具使用Jenkins，同时配合多个物理机作为Jenkins任务的执行机，这种搭配现在遇到了不少问题。没有对持续集成的环境进行固化，一旦环境出现问题，就会导致持续集成一系列任务的停滞；现在VTT的项目比较多的情况下，执行机是一种稀缺资源，有时候多个任务需要进行排队。现今，我就在考虑能不能使用docker来解决这些问题。 持续集成环境的固化 在docker的基础上，我们并不需要重新去搭建一个Jenkins服务器，我们只需要使用已有的Jenkins镜像，再根据我们自己的需要使用Dockerfile构建一个定制的Jenkins镜像，这样我们就可以在任何支持docker的环境中快速搭建持续集成环境，即便原有的环境因为某些原因崩溃了，也可以迅速恢复。 替换执行机 直接使用物理机作为Jenkins任务的执行机实际上是有几个问题的，首先每一个物理机都需要我们去配置各种各样的环境，同时因为环境没有进行隔离，我们也不可能在一个物理机上同时执行太多任务，以免造成冲突。现在这种情况，我感觉是可以使用docker作为Jenkins任务的执行环境。 通过docker，我们可以在同一个物理机中对每一个任务的环境进行隔离，确保多个任务并行不会受到影响，同时也可以执行更多任务，提高物理机的利用率。 使用docker固化各个版本的自动化案例 目前VTT主要有3个大的分支：aDesk | SDDC | aSV，这三个版本在功能上已经有了一定的区别，自动化案例也需要根据不同的版本进行修改。除此之外，部门还有各种定制包也需要在发布前进行自动化验收测试，这些定制包的功能又可能在某些地方进行改动。 在这样的情形下，我觉得单单使用版本控制工具来做区分已经有一定难度了。通过docker，我们可以将每个分支的自动化案例进行固化，构建专属的docker镜像。在没有改动的情况下我们就是用这个镜像生成的容器完成自动化测试，在分支发布了新的版本，增加或者修改了功能，我们的docker镜像也就可以跟着版本做一次更新，将相应的自动化案例补充进去。这样做，我们就有3个分支的各个版本的docker镜像，针对特定版本的定制包我们也就可以使用相应的docker镜像进行修改，然后完成相关的自动化测试。 这些docker镜像都是通过dockerfile来生成的，它们拥有一个共同的基镜像。在自动化代码本身需要进行修改时，我们就可以修改基镜像的代码，然后重新构建这些镜像，就完成了更新。 个人认为，这样做会比使用版本控制工具更方便，更利于管理。","categories":[],"tags":[],"keywords":[]},{"title":"HammerDB","slug":"HammerDB","date":"2016-02-21T14:58:18.000Z","updated":"2016-02-28T14:30:57.000Z","comments":true,"path":"2016/02/21/HammerDB/","link":"","permalink":"http://xueyaodeai.github.io/2016/02/21/HammerDB/","excerpt":"","text":"Microsoft SQL Server OLTP 测试最佳实践 这篇文档在HammerDB和SQL Server的配置方面提供建议和指导，以便达到在之后的HammerDB OLTP测试中达到比较好的吞吐量。 不过有很重要的一点需要注意，测试的最佳实践往往关注与性能，期望获取到当前系统能达到的最高吞吐量的数据；这在生产环境中未必是最好的方案，因为发生故障后的可恢复性才是生产环境关注的重点。 SQL Server 性能和可扩展性的最佳实践SQL Server 2012 在拥有2、4和8个插槽的系统中提供了出色的可扩展性。SQL Server 配置的最佳实践可以利用这些可扩展性得到最佳性能。 1. CPU、内存和IO 性能的关键性依赖是硬件 CPU是影响系统其余部分所能达到的性能级别的最重要的因素 CPU之后的下一级别是内存，想要得到最高性能，需要提供足够多的内存以缓存测试数据库的所有内容 最终，IO性能也是至关重要的。它决定了系统和CPU能够处理的吞吐量的级别。尤其在OLTP工作流中，事务日志对写入性能的要求是非常严苛的，而且IO通常是一个性能瓶颈。 为了提供可以匹配现今系统的CPU处理能力的IO性能，强烈建议使用SSD来存储数据信息和日志 2. BIOS设置 系统使用默认的BIOS设置，并不需要特意为数据库性能优化。 应该检查BIOS设置并且将设置向供应商验证，以确保它们有利于提高SQL Server的性能。 我们经常会犯一个错误，接受高性能的默认设置，让其设置一系列较低层次的BIOS选项，而不去验证这些选项的具体功能。高性能的默认设置往往会导致数据库性能表现不佳。 3. 电源选项 打开windows系统的电源选项框，选择高性能 4. 验证单线程性能 为了验证你达到了CPU单线程的最大性能，你可以创建并运行下面的存储过程stored procedure 1234567891011121314USE [tpcc] GO SET ANSI_NULLS ON GOCREATE PROCEDURE [dbo].[CPUSIMPLE]AS BEGIN DECLARE @n numeric(16,6) = 0, @a DATETIME, @b DATETIME DECLARE @f int SET @f = 1 SET @a = CURRENT_TIMESTAMP WHILE @f &lt;= 10000000 BEGIN SET @n = @n % 999999 + sqrt(@f) SET @f = @f + 1 END SET @b = CURRENT_TIMESTAMP PRINT 'Timing = ' + ISNULL(CAST(DATEDIFF(MS, @a, @b)AS VARCHAR),'') PRINT 'Res = ' + ISNULL(CAST(@n AS VARCHAR),'') END 如图2，在任意的数据库中，通过运行上面的代码创建存储过程stored procedure 右键点击CPUSIMPLE，并且点击执行存储过程stored procedure，点击OK并等待。如果运行成功会返回0值，点击信息查看程序运行时间，例如： 12Timing = 8250 Res = 873729.721235 (1 row(s) affected) 在这个案例中，存储过程运行时间为8.2秒。实际性能表现依赖于使用的CPU，通常最新的CPU都应该在10s内完成这个事务。 你可以阅读这篇博客How to Maximise CPU Performance for SQL Server on Windows,来了解更多关于这个测试的信息以及问题分析 5. 网络带宽 在一个高度可扩展的系统中，日至生成服务器和被测系统之间的网络使用率可能超过千兆速率。如果要提高带宽容量，你可以使用万兆以太网或者为两端的多个千兆以太网适配器配置NIC组，并且将两端兼容LACP的设备切换到LACP模式。首先，需要配置网络交换机，是的LACP可以使用你的交换机文档，然后在服务器管理窗口，为已经连接到同一个交换机的网卡配置NIC组。 运行一个HammerDB工作流，同时通过任务管理器确认网络带宽已经超过千兆。 6. SQL Server的属性 你可以根据你已有的硬件，使用图形化工具或者手工操作对SQL Server进行配置。下面的例子展示了内存在256GB到512GB时使用的一个配置。 12345678exec sp_configure 'show advanced options', '1'reconfigure with override exec sp_configure 'min server memory', 256000exec sp_configure 'max server memory', 512000exec sp_configure 'recovery interval','32767'exec sp_configure 'max degree of parallelism','1'exec sp_configure 'lightweight pooling','1' exec sp_configure 'priority boost', '1' exec sp_configure 'max worker threads', 3000exec sp_configure 'default trace enabled', 0go reconfigure with override 同时注意把处理器关联性Processor Affinity设置为自动模式 7. 创建数据库 受益于多个核心，在数据库服务器中直接创建HammerDB计划会更快，并且不需要通过网络来传输所有的数据。首先，提前创建一个名为tpcc(或者其他名字)的空数据库，这样做可以提前选择和配置你的存储。确保初始的DATA文件足够大(例如4槽200GB)，这样可以避免文件在测试中的持续增长，从而影响部分性能。你也可以设置自动增长属性，让文件大小在必须增长的情况下，一次增加足够的大小，避免二次性能开销。 8. 计划的创建与配置 在创建HammerDB SQL Server计划时，记得在Schema选项中选择Updated。这个计划选项可以提供更好的性能，因为Original选项需要对HammerDB的早期版本保持兼容性。 创建完成后马上对TPCC数据库进行备份，最简单的方式就是停止SQL Server服务器，然后将TPCC DATA和LOG文件复制到备份文件夹。如果要重置计划，只需要删除现有的计划，将DATA和LOG文件从备份文件夹中拷贝回来，然后使用ATTACH命令将原始的数据库添加回来，再使用下面的命令配置该计划。 123456ALTER DATABASE tpcc SET RECOVERY SIMPLEGOALTER DATABASE tpcc SET TORN_PAGE_DETECTION OFFGOALTER DATABASE tpcc SET PAGE_VERIFY NONEGO 9. 分割历史表 对于高度可扩展的系统来说，分割历史表可以减少插入冲突，无论是在你使用SQL Server Management Studio或者运行语句时。下面的语句根据仓库数量修改高亮部分的数值，每100个仓库划为1个分区。 12345678USE [tpcc]GOBEGIN TRANSACTIONCREATE PARTITION FUNCTION [HISTORY_PART](int) AS RANGE LEFT FOR VALUES (1, 100, 200, 300, 400, 500, 600, 700, 800, 900)CREATE PARTITION SCHEME [HISTORY_PART] AS PARTITION [HISTORY_PART] TO ([PRIMARY],[PRIMARY],[PRIMARY],[PRIMARY],[PRIMARY],[PRIMARY],[PRIMARY],[PRIMARY],[PRIMARY],[PRIMARY],[PRIMARY])CREATE CLUSTERED INDEX [ClusteredIndex_on_HISTORY_PART_634589363881526517] ON [dbo].[history] ( [h_w_id] )WITH (SORT_IN_TEMPDB = OFF, IGNORE_DUP_KEY = OFF, DROP_EXISTING = OFF, ONLINE = OFF) ON [HISTORY_PART]([h_w_id])DROP INDEX [ClusteredIndex_on_HISTORY_PART_634589363881526517] ON [dbo].[history] WITH ( ONLINE = OFF )COMMIT TRANSACTION 10. 调整事务日志文件的大小 当恢复间隔被设置为最大值时，会在事务日志大小超过预设的70%时设置一个检查点。因为高性能依赖于你的数据文件的IO写入速率，设置检查点时会对IO造成显著的影响，下面的HammerDB事务统计图说明了这一点。 如果要观察checkpoint事件，需要设置DBCC命令追踪3502，3504和3605并且打开错误日志。 2014-01-15 14:04:35.18 spid56 DBCC TRACEON 3502, server process ID (SPID) 56. This is an informational message only; no user action is required. 2014-01-15 14:06:52.74 spid56 DBCC TRACEON 3502, server process ID (SPID) 56. This is an informational message only; no user action is required. 2014-01-15 14:06:52.74 spid56 DBCC TRACEON 3502, server process ID (SPID) 56. This is an informational message only; no user action is required. 下面的例子告诉我们检查点的设置以1GB/s的速度写入数据，过程持续了14.7s，期间伴随着性能的显著下降。 2014-01-16 11:41:11.75 spid20s FlushCache: cleaned up 1932082 bufs with 948934 writes in 14739 ms (avoided 25317 new dirty bufs) for db 5:0 2014-01-16 11:41:11.75 spid20s average throughput: 1024.11 MB/sec, I/O saturation: 418155, context switches 562834 2014-01-16 11:41:11.75 spid20s last target outstanding: 31729, avgWriteLatency 26 2014-01-16 11:41:11.75 spid20s About to log Checkpoint end. 如果要将设置检查点的事件推迟到测试完成后进行，需要重新设置日志文件的大小。日志文件太小会导致检查点在测试完成之前进行设置，文件设置太大又会影响性能。下面的例子将日志文件的大小设置为64GB。 1234use tpccdbcc shrinkfile('tpcc_log',truncateonly)alter database tpcc modify file (name='tpcc_log', size=64000)dbcc loginfo('tpcc') 如图11所示，勾选Checkpoint when complete进行设置，让检查点在测试完成后进行设置。 如图12所示，检验完整测试的性能表现，确保事务统计曲线是平坦的，这表明SQL Server的性能没有因为设置检查点而受到影响。 11. 监控 使用Open Source Fusion-IO MS SQL Server scripts找出性能瓶颈。在下面的例子中，写日志是主要的性能瓶颈，因此，增大日志写入的IO带宽是提升性能的最佳手段(此时CPU未饱和)。 如果单负载生成客户端(非被测服务器)上面的CPU已经满负载，我们可以使用多个负载测试客户端。通过主从功能，可以同时使用2个客户端驱动负载。如果服务器上面的CPU没有满负载也没有找到其他的性能瓶颈例如IO或者网络，那么我们可以在负载生成客户端增加虚拟用户数量。 12. 处理器组相关 Windows Server 2008以及更早期版本最高只支持64个处理器。Windows Server 2008 R2、2012和2012 R2最高支持256个处理器并且将这些处理器每64个划分为1个处理器组，通过管理处理器组的方式提高Windows的性能。例如，拥有120个逻辑处理器的Windows Server 2012 R2将这些处理器分为2个处理器组，每组60个处理器。HammerDB Matrix工具可以用来说明SQL Server中处理器组的用法。 绝大多数应用(包括HammerDB客户端都只能运行在一个处理器组中)。尽管SQL Server能够跨处理器组进行操作，但可能将单个测试的客户端的连接限制在一个或几个处理器组。 一旦初始分配sessions的时候没有跨处理器组，那么性能和CPU利用率可能会受到人为限制。当处理器组限制出现在“线程和CPU”的顶级等待事件中，使用之前提及的FusionIO Monitoring Scripts。运行测试的目的是充分利用所有CPU以达到更好的性能。修改调度时间会影响处理器组的调度。为了达到这个平衡，在HammerDB虚拟用户选项中，将User Delay参数修改为10ms(这个表示上一个用户登录后，下一个用户需要等待10ms)。 缩短连接的时间，通常可以保证连接在服务端的连接均匀分布。可以使用图17中展示的HammerDB Metrics tool对系统进行监控，保证资源的有效利用","categories":[],"tags":[{"name":"HammerDB","slug":"HammerDB","permalink":"http://xueyaodeai.github.io/tags/HammerDB/"},{"name":"Test","slug":"Test","permalink":"http://xueyaodeai.github.io/tags/Test/"}],"keywords":[]},{"title":"Vue.js代码提交规范","slug":"Vuejs代码提交规范","date":"2015-12-14T14:20:47.000Z","updated":"2015-12-15T16:24:24.000Z","comments":true,"path":"2015/12/14/Vuejs代码提交规范/","link":"","permalink":"http://xueyaodeai.github.io/2015/12/14/Vuejs代码提交规范/","excerpt":"","text":"issue报告指南 这个报告的问题列表只应该包含bug报告和特性的请求。对于简单的问题，可以使用Gitter或者官方论坛。 尝试搜索你的问题，也许已经有人答复了这个问题，甚至已经在开发分支中解决了。 检查这个问题在最新的稳定版Vue.js中是否能够重现。如果你在使用预览版，请标明你正在使用的版本。 你必须清楚地描述所有必要的步骤，以便重现你发现的这个问题。没用明确重现步骤的问题将不会被分类。如果一个问题被标记为”需要重现(need repro)”，而问题的发现者在5天内没有进一步的说明，这个问题就会被关闭。 强烈建议使用JSFiddle来演示你的问题。你可以使用模板，这里已经包含了最新版本的Vue.js。 如果你的问题已经被解决了，但是问题报告还处于open状态，你应该毫不犹豫地关掉它。如果你自己找到了解决方案，你可以留下你的解决办法，以便帮助遇到这个问题的其他人。 Pull Request指南 从dev创建一个新分支再合并回来。 只在src目录下工作，不要把dist目录的文件提交上来。 如果有太多小的修改，可以合并提交。 遵守代码规范 确保默认的grunt任务通过(详情见开发安装步骤) 如果是添加新的特性: 添加相应的测试案例。 提供添加这个特性的理由。理论上来说，你应该先提交一个issue建议并且让它通过，然后你才应该实现它。 如果是修复一个bug: 请在Pull Request中详细描述这个bug的信息。有demo最好。 可以的话，请添加合适的测试案例进行覆盖。 代码规范 如非必要请不要使用分号 遵从JSDoc 使用2个空格进行缩进 多重var声明 在function和函数名称后面保留1个空格 在参数之间保留1个空格，但不要跟括号保留空格。 对比较长的三元判断进行分割，例如: 123var a = superLongConditionalStatement ? 'yep' : 'nope' 如果有疑问，请阅读源码 开发安装步骤 你需要安装Node.js。 123$ npm install# install pre-commit lint hook$ npm run install-hook Dev模式: 开发过程中，监控并自动构建dist/vue.js，并且在http://localhost:8080输出单元测试结果: 1$ npm run dev 链接: 1$ npm run lint 构建: 1$ npm run build 运行默认的测试套: 1$ npm run build 默认的测试脚本会执行以下步骤:链接-&gt;单元覆盖测试-&gt;构建-&gt;端对端测试。在提交Pull Request之前请确保这个测试成功通过。 单元测试使用Jasmine，并在Karma上运行。至于端对端测试则是运行在CasperJS之上。","categories":[],"tags":[{"name":"Vue.js","slug":"Vue-js","permalink":"http://xueyaodeai.github.io/tags/Vue-js/"},{"name":"JavaScript","slug":"JavaScript","permalink":"http://xueyaodeai.github.io/tags/JavaScript/"}],"keywords":[]},{"title":"记忆中的2班","slug":"使用hexo和Github-pages搭建个人blog","date":"2015-12-12T10:49:18.000Z","updated":"2016-02-28T14:48:13.000Z","comments":true,"path":"2015/12/12/使用hexo和Github-pages搭建个人blog/","link":"","permalink":"http://xueyaodeai.github.io/2015/12/12/使用hexo和Github-pages搭建个人blog/","excerpt":"","text":"愿我们彼此铭刻，直到生命的尽头。","categories":[],"tags":[{"name":"Life","slug":"Life","permalink":"http://xueyaodeai.github.io/tags/Life/"}],"keywords":[]}]}